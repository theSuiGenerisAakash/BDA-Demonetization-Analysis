View(tweets)
load("E:/RStudio/workspace/WordCloudTwitter/twitter authentication.Rdata")
no.of.tweets<-1500
View(demo.Tweets)
View(tweets)
View(demo.Tweets)
rm(demo.Tweets)
tweets.text
save.image("E:/RStudio/workspace/WordCloudTwitter/demonetization_tweets_analysis.RData")
load("E:/RStudio/workspace/WordCloudTwitter/twitter authentication.Rdata")
load("E:/RStudio/workspace/WordCloudTwitter/demonetization_tweets_analysis.RData")
load(twitteR)
load("twitteR")
installed.packages()
install.packages(twitteR)
install.packages("twitteR")
load("dplyr")
setwd("E:/RStudio/workspace/WordCloudTwitter")
load("twitteR")
load(ROAuth)
load("E:/RStudio/workspace/WordCloudTwitter/demonetization_tweets_analysis.RData")
tweets <- searchTwitter(search.string, no.of.tweets, cainfo=”cacert.pem”, lang=”en”)
library(ROAuth)
library(twitteR)
library(tm)
library(wordcloud)
library(RColorBrewer)
setup_twitter_oauth(cred$consumerKey,cred$consumerSecret,cred$oauthKey,cred$oauthSecret)
setup_twitter_oauth(cred$consumerKey,cred$consumerSecret,cred$oauthKey,cred$oauthSecret)
tweets <- searchTwitter(search.string, no.of.tweets, cainfo=”cacert.pem”, lang=”en”)
tweets <- searchTwitter(search.string, no.of.tweets, lang=”en”)
tweets <- searchTwitter(search.string, n = no.of.tweets, lang=”en”)
tweets <- searchTwitter(search.string,n=no.of.tweets,lang = 'en')
tweets.text <- sapply(tweets, function(x) x$getText())
#convert all text to lower case
tweets.text <- tolower(tweets.text)
# Replace blank space (“rt”)
tweets.text <- gsub("rt", "", tweets.text)
# Replace @UserName
tweets.text <- gsub("@\\w+", "", tweets.text)
# Remove punctuation
tweets.text <- gsub("[[:punct:]]", "", tweets.text)
# Remove links
tweets.text <- gsub("http\\w+", "", tweets.text)
# Remove tabs
tweets.text <- gsub("[ |\t]{2,}", "", tweets.text)
# Remove blank spaces at the beginning
tweets.text <- gsub("^ ", "", tweets.text)
# Remove blank spaces at the end
tweets.text <- gsub(" $", "", tweets.text
\
#convert all text to lower case
tweets.text <- tolower(tweets.text)
# Replace blank space (“rt”)
tweets.text <- gsub("rt", "", tweets.text)
# Replace @UserName
tweets.text <- gsub("@\\w+", "", tweets.text)
# Remove punctuation
tweets.text <- gsub("[[:punct:]]", "", tweets.text)
# Remove links
tweets.text <- gsub("http\\w+", "", tweets.text)
# Remove tabs
tweets.text <- gsub("[ |\t]{2,}", "", tweets.text)
# Remove blank spaces at the beginning
tweets.text <- gsub("^ ", "", tweets.text)
# Remove blank spaces at the end
tweets.text <- gsub(" $", "", tweets.text)
tweets.text<-tm_map(tweets.text,tolower)
rm(demo.Tweets.text)
tweets.text
tweets.text <- tolower(tweets.text)
library(stringi)
library(stringr)
tweets.text<-str_replace_all(tweets.text,"[^[:graph:]]", ""))
tweets.text<-str_replace_all(tweets.text,"[^[:graph:]]", "")
#create corpus
tweets.text.corpus <- Corpus(VectorSource(tweets.text))
#clean up by removing stop words
tweets.text.corpus <- tm_map(tweets.text.corpus, function(x)removeWords(x,stopwords()))
library(wordcloud)
wordcloud(tweets.text.corpus,min.freq = 2, scale=c(4,0.5),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 100)
tweets <- searchTwitter(search.string,n=no.of.tweets,lang = 'en')
tweets.text <- sapply(tweets, function(x) x$getText())
#convert all text to lower case
tweets.text <- tolower(tweets.text)
# Replace blank space (“rt”)
tweets.text <- gsub("rt", "", tweets.text)
# Replace @UserName
tweets.text <- gsub("@\\w+", "", tweets.text)
# Remove punctuation
tweets.text <- gsub("[[:punct:]]", "", tweets.text)
# Remove links
tweets.text <- gsub("http\\w+", "", tweets.text)
# Remove tabs
tweets.text <- gsub("[ |\t]{2,}", "", tweets.text)
# Remove blank spaces at the beginning
tweets.text <- gsub("^ ", "", tweets.text)
# Remove blank spaces at the end
tweets.text <- gsub(" $", "", tweets.text)
tweets.text<-str_replace_all(tweets.text,"[^[:graph:]]", " ")
tweets.text
#convert all text to lower case
tweets.text <- tolower(tweets.text)
# Replace blank space (“rt”)
tweets.text <- gsub("rt", "", tweets.text)
# Replace @UserName
tweets.text <- gsub("@\\w+", "", tweets.text)
# Remove punctuation
tweets.text <- gsub("[[:punct:]]", "", tweets.text)
# Remove links
tweets.text <- gsub("http\\w+", "", tweets.text)
# Remove tabs
tweets.text <- gsub("[ |\t]{2,}", "", tweets.text)
# Remove blank spaces at the beginning
tweets.text <- gsub("^ ", "", tweets.text)
# Remove blank spaces at the end
tweets.text <- gsub(" $", "", tweets.text)
#create corpus
tweets.text.corpus <- Corpus(VectorSource(tweets.text))
#clean up by removing stop words
tweets.text.corpus <- tm_map(tweets.text.corpus, function(x)removeWords(x,stopwords()))
wordcloud(tweets.text.corpus,min.freq = 2, scale=c(4,0.5),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 100)
wordcloud(tweets.text.corpus,min.freq = 2, scale=c(7,0.5),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 100)
wordcloud(tweets.text.corpus, scale=c(4,0.2),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 20)
tweets.text
wordcloud(tweets.text.corpus, scale=c(4,0.2),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 20)
wordcloud(tweets.text.corpus, scale=c(7,0.2),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 20)
search.string='#demonetization OR demonetization OR #noteban OR note ban'
tweets <- searchTwitter(search.string,n=no.of.tweets)
tweets.text <- sapply(tweets, function(x) x$getText())
tweets.text<-str_replace_all(tweets.text,"[^[:graph:]]", " ")
#convert all text to lower case
tweets.text <- tolower(tweets.text)
# Replace blank space (“rt”)
tweets.text <- gsub("rt", "", tweets.text)
# Replace @UserName
tweets.text <- gsub("@\\w+", "", tweets.text)
# Remove punctuation
tweets.text <- gsub("[[:punct:]]", "", tweets.text)
# Remove links
tweets.text <- gsub("http\\w+", "", tweets.text)
# Remove tabs
tweets.text <- gsub("[ |\t]{2,}", "", tweets.text)
# Remove blank spaces at the beginning
tweets.text <- gsub("^ ", "", tweets.text)
# Remove blank spaces at the end
tweets.text <- gsub(" $", "", tweets.text)
#create corpus
tweets.text.corpus <- Corpus(VectorSource(tweets.text))
#clean up by removing stop words
tweets.text.corpus <- tm_map(tweets.text.corpus, function(x)removeWords(x,stopwords()))
wordcloud(tweets.text.corpus,min.freq = 2, scale=c(4,0.5),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 100)
wordcloud(tweets.text.corpus,min.freq = 100, scale=c(5,0.7),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 100)
wordcloud(tweets.text.corpus,min.freq = 50, scale=c(5,0.7),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 100)
wordcloud(tweets.text.corpus, scale=c(5,0.7),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 100)
warnings()
wordcloud(tweets.text.corpus, scale=c(5,0.7),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 100)
wordcloud(tweets.text.corpus, scale=c(5,0.5),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 100)
wordcloud(tweets.text.corpus, scale=c(5,0.9),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 100)
wordcloud(tweets.text.corpus, scale=c(3,0.7),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 100)
wordcloud(tweets.text.corpus, scale=c(4,0.4),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 100)
wordcloud(tweets.text.corpus, scale=c(4,0.7),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 100)
wordcloud(tweets.text.corpus, scale=c(5,0.7),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 100)
wordcloud(tweets.text.corpus, scale=c(4,0.7),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 100)
save.image("E:/RStudio/workspace/WordCloudTwitter/demonetization_tweets_analysis.RData")
load("E:/RStudio/workspace/WordCloudTwitter/twitter authentication.Rdata")
load("E:/RStudio/workspace/WordCloudTwitter/WordCloudTwitter.RData")
View(tweets.text.corpus)
library("ROAuth")
library("twitteR")
library("tm")
library("wordcloud")
library("RColorBrewer")
library("stringr")
setup_twitter_oauth(cred$consumerKey,cred$consumerSecret,cred$oauthKey,cred$oauthSecret)
load("E:/RStudio/workspace/WordCloudTwitter/twitter authentication.Rdata")
setup_twitter_oauth(cred$consumerKey,cred$consumerSecret,cred$oauthKey,cred$oauthSecret)
library("ROAuth")
library("twitteR")
library("tm")
library("wordcloud")
library("RColorBrewer")
load("E:/RStudio/workspace/WordCloudTwitter/WordCloudTwitter.RData")
load("E:/RStudio/workspace/BDA_Assignment_DemonetizationAnalysis/WordCloudTwitter/twitter authentication.Rdata")
load("E:/RStudio/workspace/BDA_Assignment_DemonetizationAnalysis/WordCloudTwitter/WordCloudTwitter.RData")
load("E:/RStudio/workspace/BDA_Assignment_DemonetizationAnalysis/WordCloudTwitter/twitter authentication.Rdata")
#Word Cloud module
#loading up required libraries
library("ROAuth")
library("twitteR")
library("tm")
library("wordcloud")
library("RColorBrewer")
library("stringr") #For emojis and non-Unicode character
#Direct authentication to twitter account
setup_twitter_oauth(cred$consumerKey,cred$consumerSecret,cred$oauthKey,cred$oauthSecret)
#Setting up search string
search.string<-"#demonetization OR demonetization OR #noteban OR note ban"
#Setting up the no of tweets to be retrieved
no.of.tweets<-1500
#Retrieving tweets data
tweets <- searchTwitter(search.string,n=no.of.tweets,lang = 'en')
#get texts of the tweets
tweets.text <- sapply(tweets, function(x) x$getText())
#removing non-Unicode characters
tweets.text<-str_replace_all(tweets.text,"[^[:graph:]]", " ")
tweets.text
#convert all text to lower case
tweets.text <- tolower(tweets.text)
# Replace blank space (“rt”)
tweets.text <- gsub("rt", "", tweets.text)
# Replace @UserName
tweets.text <- gsub("@\\w+", "", tweets.text)
# Remove punctuation
tweets.text <- gsub("[[:punct:]]", "", tweets.text)
# Remove links
tweets.text <- gsub("http\\w+", "", tweets.text)
# Remove tabs
tweets.text <- gsub("[ |\t]{2,}", "", tweets.text)
# Remove blank spaces at the beginning
tweets.text <- gsub("^ ", "", tweets.text)
# Remove blank spaces at the end
tweets.text <- gsub(" $", "", tweets.text)
#create corpus
tweets.text
